
# ğŸ§  Production-Ready Multilingual RAG System for Tender Documents

**RAGbot** is a production-grade Retrieval-Augmented Generation (RAG) system specifically designed for **German public tender documents** (Vergabeunterlagen) with full multilingual support.

Query unstructured procurement data in **German or English** and receive **accurate, grounded, source-cited answers** through an intuitive chat interface.

This system runs **100% offline** on your local machine using:
- **Qdrant** for vector storage
- **Jina Embeddings v3** (1024-D) for semantic search  
- **Ollama** for local LLM inference (Qwen2.5, Llama, Mistral)
- **Streamlit** for the web interface

âœ… **Production-Ready**: Fixed syntax errors, robust error handling, metadata integration, comprehensive documentation

---

## âœ¨ Key Features

### Core RAG Capabilities
* ğŸ” **Multilingual Semantic Search** - Query in German or English, retrieve from both
* ğŸ“‘ **Rich Document Support** - PDF, Excel, DOCX, scanned files (OCR via Tesseract)
* âš¡ **High-Performance Embeddings** - Jina v3 (1024-D) with GPU acceleration
* ğŸ—„ï¸ **Qdrant Vector DB** - Fast, persistent semantic search with 29,086+ chunks
* ğŸ¤– **Local LLM Generation** - Ollama (Qwen2.5:1.5b default, supports Llama/Mistral)
* ğŸ“Š **Metadata-Aware Routing** - Direct DTAD-ID lookups, date/region filters
* ğŸ¯ **Citation Grounding** - Every answer cites sources with [1], [2] references
* ï¿½ **Privacy-First** - Everything runs locally, zero external API calls

### Production Features
* âœ… **Graceful Error Handling** - Handles missing collections, network issues
* ï¿½ **Metadata Integration** - 112 tenders with normalized DTAD-ID, dates, regions  
* ğŸ§ª **Test Suite** - Comprehensive test queries and validation scripts
* ğŸ“– **Complete Documentation** - Quickstart, production guide, testing guide
* ğŸš€ **One-Command Deployment** - `deploy_production.py` script included

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart LR
    A[ğŸ“„ Tender Docs (PDF, Excel, Word, OCR)] --> B[ğŸ§¹ Parser & Metadata Cleaner]
    B --> C[âœ‚ï¸ Chunking + GPU Embeddings]
    C --> D[(ğŸ—„ï¸ Qdrant Vector DB)]
    D --> E[ğŸ” Retriever (Top-K Search)]
    E --> F[ğŸ¤– Cross-Encoder Reranker]
    F --> G[ğŸ§  LLM via Ollama]
    G --> H[ğŸ“ Answer Generator]
    H --> I[ğŸ’» Streamlit UI]

    subgraph User
        Q[â“ User Query]
        R[ğŸ“‘ Structured Answer + Sources]
    end

    Q --> E
    I --> R
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+ (Conda environment recommended)
- Docker (for Qdrant)
- Ollama (for local LLMs)
- 8GB+ RAM, GPU recommended for embeddings

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/ShalinVachheta017/ragbot-core.git
cd ragbot-core
```

### 2ï¸âƒ£ Set Up Environment

```bash
# Create conda environment
conda create -n mllocalag python=3.10
conda activate mllocalag

# Install dependencies
pip install -r requirements.txt
pip install pytesseract  # For OCR support
```

### 3ï¸âƒ£ Start Qdrant Vector Database

```bash
docker compose up -d
# Verify: http://localhost:6333/dashboard
```

### 4ï¸âƒ£ Install Ollama Models

```bash
# Install Ollama from https://ollama.ai
ollama pull qwen2.5:1.5b
ollama pull llama3.2:1b  # Optional alternative
```

### 5ï¸âƒ£ Index Your Documents

```bash
# Parse metadata
python scripts/parse_excel.py

# Embed and index documents (takes 5-10 minutes)
python scripts/embed.py --mode fresh

# Verify indexing
curl http://localhost:6333/collections/tender_chunks
```

### 6ï¸âƒ£ Launch Streamlit UI

```bash
streamlit run ui/app_streamlit.py
# Open browser: http://localhost:8501
```

**Ready!** Try queries like:
- `"Was ist DTAD-ID 20046891?"`
- `"Show me tenders from 2024"`
- `"Tenders in Dresden region"`

---

## ğŸ–¥ï¸ UI Preview

* Query tender docs with natural language (DE/EN)
* Filter by metadata (e.g. CPV codes, filenames)
* Adjust `Top-K results` & reranker candidates
* Answers include **citations + categories + summaries**

---

## ğŸ“‚ Project Structure

```
multilingual-ragbot/
â”œâ”€â”€ core/                          # Core RAG components
â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”œâ”€â”€ qa.py                     # Q&A and retrieval logic
â”‚   â”œâ”€â”€ search.py                 # Dense vector search
â”‚   â”œâ”€â”€ domain.py                 # Data models
â”‚   â”œâ”€â”€ io.py                     # File I/O utilities
â”‚   â””â”€â”€ logger.py                 # Logging configuration
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app_streamlit.py          # ğŸ–¥ï¸ Main Streamlit interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ embed.py                  # Document embedding pipeline
â”‚   â”œâ”€â”€ ingest.py                 # Document ingestion
â”‚   â”œâ”€â”€ parse_excel.py            # Metadata parser
â”‚   â””â”€â”€ search.py                 # Search utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ metadata/                 # Tender metadata (cleaned_metadata.xlsx)
â”‚   â”œâ”€â”€ extract/                  # Extracted document text
â”‚   â”œâ”€â”€ raw/                      # Original documents
â”‚   â””â”€â”€ logs/                     # Processing logs
â”œâ”€â”€ docs/                          # ğŸ“– Documentation
â”‚   â”œâ”€â”€ TESTING_GUIDE.md          # Testing procedures
â”‚   â”œâ”€â”€ SYSTEM_REVIEW.md          # System architecture review
â”‚   â””â”€â”€ TEST_QUERIES.md           # Example test queries
â”œâ”€â”€ QUICKSTART.md                  # âš¡ Quick start guide
â”œâ”€â”€ PRODUCTION_GUIDE.md            # ğŸš€ Production deployment guide
â”œâ”€â”€ deploy_production.py           # One-command deployment
â”œâ”€â”€ docker-compose.yml             # Qdrant service configuration
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 5 minutes
- **[PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md)** - Production deployment
- **[docs/TESTING_GUIDE.md](docs/TESTING_GUIDE.md)** - Testing procedures
- **[docs/TEST_QUERIES.md](docs/TEST_QUERIES.md)** - Example queries

## ğŸ¯ Example Queries

The system handles various query types:

**Direct ID Lookups:**
```
"Was ist DTAD-ID 20046891?"
"Show me tender 20047108"
```

**Temporal Queries:**
```
"Show me tenders from 2024"
"What tenders were published in March?"
```

**Geographic Filters:**
```
"Tenders in Dresden"
"Show me projects in Berlin region"
```

**Semantic Questions:**
```
"Welche Unterlagen sind fÃ¼r VOB-konforme Ausschreibungen erforderlich?"
"What are the technical specifications for IT projects?"
"Mindestlohn requirements in construction tenders"
```

**Metadata Routing:**
- DTAD-ID queries â†’ Direct metadata lookup (instant)
- Date/year queries â†’ Metadata filtering  
- Semantic queries â†’ Vector search with context

---

## ğŸ”® Roadmap & Future Enhancements

### ğŸš§ Planned Core Improvements

**Retrieval Enhancement (High Priority)**
- ï¿½ **Hybrid Search** - Combine dense (semantic) + sparse (BM25) retrieval for better accuracy
  - Implement BM25 keyword matching alongside vector search
  - Weighted fusion (e.g., 70% dense + 30% sparse)
  - Expected improvement: +15% recall, especially for exact term matches
  
- ğŸ¯ **Reranker Integration** - Cross-encoder model to reorder retrieved chunks
  - Model: `ms-marco-MiniLM-L-6-v2` or `bge-reranker-large`
  - Two-stage pipeline: Fast retrieval (top-100) â†’ Accurate reranking (top-8)
  - Expected improvement: +20% precision, better relevance
  
- ğŸ“Š **Query Classification** - Route queries to optimal retrieval strategy
  - Factual queries â†’ Hybrid search
  - Semantic queries â†’ Dense only
  - ID lookups â†’ Metadata (already implemented âœ…)

**Evaluation & Quality (High Priority)**
- ğŸ“ˆ **Automated Evaluation Framework**
  - Metrics: Hit Rate, MRR, Precision@k, Recall@k, NDCG
  - Faithfulness scoring (grounding check)
  - Test suite with 50+ queries across categories
  - Regression testing before deployments
  
- ğŸ§ª **A/B Testing Infrastructure**
  - Compare retrieval strategies (dense vs hybrid vs reranked)
  - LLM model comparison (Qwen vs Llama vs Mistral)
  - Prompt engineering experiments
  - User feedback collection

**Monitoring & Observability (Medium Priority)**
- ğŸ“‰ **Production Monitoring**
  - Query latency tracking (p50, p95, p99)
  - Error rate monitoring (Qdrant, Ollama, parsing)
  - Cache hit rate metrics
  - User query analytics (popular queries, failure patterns)
  
- ï¿½ **Alerting System**
  - Latency threshold alerts (>5s response time)
  - Error rate spikes (>5% failures)
  - System health checks (Qdrant, Ollama availability)
  - Daily/weekly metrics reports

### ğŸŒŸ Advanced Features

**Semantic & Retrieval**
- ğŸ§  **Semantic Chunking** - Replace fixed-size chunks with sentence-aware splitting
  - Prevents mid-sentence cuts
  - Preserves semantic meaning
  - Library: LangChain `RecursiveCharacterTextSplitter`

- ğŸ”— **Graph RAG** - Build knowledge graph from tender relationships
  - Entity extraction (companies, locations, amounts)
  - Relationship mapping (tender â†’ contractor â†’ region)
  - Multi-hop reasoning ("Find all tenders by company X in region Y")

- ï¿½ **Multilingual Query Expansion**
  - Auto-translate queries (German â†” English â†” French)
  - Retrieve from all languages simultaneously
  - Unified ranking across languages

**Intelligence & Automation**
- ğŸ¤– **Agentic RAG** - Multi-step reasoning for complex queries
  - "Compare tenders 20046891 and 20046893" â†’ Multi-document analysis
  - "What changed in Dresden tenders from 2023 to 2024?" â†’ Temporal analysis
  - Tool use: Calculator for budget analysis, date parsing

- ğŸ’¡ **Smart Summarization**
  - Tender summaries on-demand
  - Highlight key requirements, deadlines, budgets
  - Multi-document summarization (region overview, category trends)

- ï¿½ **Proactive Notifications**
  - Alert when new tenders match saved criteria
  - Deadline reminders
  - Competitive intelligence (similar past tenders)

**Data & Documents**
- ğŸ“· **Multimodal RAG** - Handle images, tables, charts
  - Vision LLM (LLaVA, GPT-4V) for images
  - Table extraction and structured parsing
  - Diagram understanding (flowcharts, blueprints, site plans)

- ğŸ“Š **Structured Data Extraction**
  - Auto-extract: budgets, deadlines, requirements, contact info
  - Store in structured DB (PostgreSQL) alongside vectors
  - Enable SQL queries + semantic search combination

- ğŸ“„ **Document Generation**
  - Generate bid responses from templates
  - Compliance checklist generation
  - Requirement matching reports

**User Experience**
- ğŸ“ˆ **Analytics Dashboard**
  - Tender volume trends (by region, category, time)
  - Budget analysis (average, min, max by category)
  - CPV code distribution
  - Interactive visualizations (Plotly, Streamlit charts)

- ğŸ¨ **Enhanced UI**
  - Dark/light mode toggle
  - Export answers to PDF/Word
  - Bookmark/favorite queries
  - Collaborative features (share queries, annotations)

- ğŸ—£ï¸ **Voice Interface** (Experimental)
  - Speech-to-text for queries
  - Text-to-speech for answers
  - Hands-free tender review

**Integration & Deployment**
- ğŸŒ **API Development**
  - FastAPI REST API for programmatic access
  - WebSocket support for streaming answers
  - API key authentication
  - Rate limiting and quota management

- ğŸ”— **External Integrations**
  - Tender portals (TED, Bund.de, regional platforms)
  - SharePoint/OneDrive document sync
  - Email notifications (SendGrid, AWS SES)
  - Slack/Teams bot integration

- ï¿½ **Production Deployment**
  - Kubernetes manifests (deployments, services, ingress)
  - Horizontal pod autoscaling (HPA)
  - CI/CD pipeline (GitHub Actions)
  - Multi-environment setup (dev, staging, prod)

**Enterprise & Security**
- ğŸ” **Security Hardening**
  - User authentication (OAuth2, SSO)
  - Role-based access control (RBAC)
  - Audit logs (who queried what, when)
  - Data encryption at rest and in transit

- ğŸ¢ **Multi-Tenancy**
  - Separate collections per organization
  - Tenant isolation
  - Custom branding per tenant

- ğŸ“¦ **Backup & Disaster Recovery**
  - Automated Qdrant backups
  - Point-in-time recovery
  - Geo-redundant storage

### ğŸ“… Implementation Timeline

**Phase 1 (Months 1-2): Core Improvements**
- âœ… Hybrid search implementation
- âœ… Reranker integration
- âœ… Basic evaluation framework
- âœ… Monitoring dashboard

**Phase 2 (Months 3-4): Quality & Scale**
- Semantic chunking
- A/B testing infrastructure
- Production alerting
- Graph RAG prototype

**Phase 3 (Months 5-6): Advanced Features**
- Agentic RAG
- Multimodal support (tables, images)
- Analytics dashboard
- API development

**Phase 4 (Months 7-9): Enterprise Ready**
- Authentication & RBAC
- Multi-tenancy
- External integrations
- Kubernetes deployment

---

## ğŸ“Š Current Limitations & Known Issues

**Retrieval:**
- âŒ No hybrid search (dense-only, misses exact keyword matches)
- âŒ No reranking (retrieved chunks not optimally ordered)
- âŒ Fixed 512-char chunks (may split important context)

**Generation:**
- âš ï¸ Small LLM (1.5B params) - occasionally struggles with complex German
- âš ï¸ No query decomposition (complex multi-part questions need manual breakdown)
- âš ï¸ Limited citation granularity (chunk-level, not sentence-level)

**Monitoring:**
- âŒ No production metrics tracking
- âŒ No error alerting
- âŒ No user feedback loop
- âŒ No A/B testing infrastructure

**Scale:**
- âš ï¸ Single-node Qdrant (no replication)
- âš ï¸ No caching layer (repeated queries not optimized)
- âš ï¸ GPU not utilized for LLM (CPU inference slower)

**See [INTERVIEW_PREP_GUIDE.md](INTERVIEW_PREP_GUIDE.md) for detailed discussion of limitations and solutions.**

---

## ğŸ› Troubleshooting

**Qdrant Connection Error:**
```bash
# Check Qdrant is running
curl http://localhost:6333/collections
# Restart if needed
docker compose restart
```

**Empty Search Results:**
```bash
# Verify documents are indexed
curl http://localhost:6333/collections/tender_chunks
# Re-index if point_count is 0
python scripts/embed.py --mode fresh
```

**Ollama Model Not Found:**
```bash
ollama list  # Check installed models
ollama pull qwen2.5:1.5b  # Install if missing
```

**Import Errors:**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“œ License

MIT License - free to use and adapt with attribution.

---

## ğŸ‘¤ Author

**Shalin Vachheta**  
GitHub: [@ShalinVachheta017](https://github.com/ShalinVachheta017)

---

## ğŸ™ Acknowledgments

- **Jina AI** - Embeddings model
- **Qdrant** - Vector database
- **Ollama** - Local LLM inference
- **Streamlit** - UI framework
- German procurement community for test data

---

**â­ Star this repo if you find it useful!**

