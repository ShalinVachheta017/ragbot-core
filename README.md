
# üß† Production-Ready Multilingual RAG System for Tender Documents

**RAGbot** is a production-grade Retrieval-Augmented Generation (RAG) system specifically designed for **German public tender documents** (Vergabeunterlagen) with full multilingual support.

Query unstructured procurement data in **German or English** and receive **accurate, grounded, source-cited answers** through an intuitive chat interface.

This system runs **100% offline** on your local machine using:
- **Qdrant** for vector storage
- **Jina Embeddings v3** (1024-D) for semantic search  
- **Ollama** for local LLM inference (Qwen2.5, Llama, Mistral)
- **Streamlit** for the web interface

---

## ‚ú® Key Features

### Core RAG Capabilities
* üîé **Multilingual Semantic Search** - Query in German or English, retrieve from both
* üìë **Rich Document Support** - PDF, Excel, DOCX, scanned files (OCR via Tesseract)
* ‚ö° **High-Performance Embeddings** - Jina v3 (1024-D) with GPU acceleration
* üóÑÔ∏è **Qdrant Vector DB** - Fast, persistent semantic search with 29,086+ chunks
* ü§ñ **Local LLM Generation** - Ollama (Qwen2.5:1.5b default, supports Llama/Mistral)
* üìä **Metadata-Aware Routing** - Direct DTAD-ID lookups, date/region filters
* üéØ **Citation Grounding** - Every answer cites sources with [1], [2] references
* ÔøΩ **Privacy-First** - Everything runs locally, zero external API calls

### Production Features
* ‚úÖ **Graceful Error Handling** - Handles missing collections, network issues
* ÔøΩ **Metadata Integration** - tenders with normalized DTAD-ID, dates, regions  
* üß™ **Test Suite** - Comprehensive test queries and validation scripts
* üìñ **Complete Documentation** - Quickstart, production guide, testing guide
* üöÄ **One-Command Deployment** - `deploy_production.py` script included

---

## üèóÔ∏è System Architecture

```mermaid
flowchart LR
    A[üìÑ Tender Docs (PDF, Excel, Word, OCR)] --> B[üßπ Parser & Metadata Cleaner]
    B --> C[‚úÇÔ∏è Chunking + GPU Embeddings]
    C --> D[(üóÑÔ∏è Qdrant Vector DB)]
    D --> E[üîé Retriever (Top-K Search)]
    E --> F[ü§ñ Cross-Encoder Reranker]
    F --> G[üß† LLM via Ollama]
    G --> H[üìù Answer Generator]
    H --> I[üíª Streamlit UI]

    subgraph User
        Q[‚ùì User Query]
        R[üìë Structured Answer + Sources]
    end

    Q --> E
    I --> R
```

![System Architecture Diagram](diagram.png)

---

## üöÄ Quick Start

### Prerequisites
- Python 3.10+ (Conda environment recommended)
- Docker (for Qdrant)
- Ollama (for local LLMs)
- 8GB+ RAM, GPU recommended for embeddings

### 1Ô∏è‚É£ Clone Repository

```bash
git clone https://github.com/ShalinVachheta017/ragbot-core.git
cd ragbot-core
```

### 2Ô∏è‚É£ Set Up Environment

```bash
# Create conda environment
conda create -n mllocalag python=3.10
conda activate mllocalag

# Install dependencies
pip install -r requirements.txt
pip install pytesseract  # For OCR support
```

### 3Ô∏è‚É£ Start Qdrant Vector Database

```bash
docker compose up -d
# Verify: http://localhost:6333/dashboard
```

### 4Ô∏è‚É£ Install Ollama Models

```bash
# Install Ollama from https://ollama.ai
ollama pull qwen2.5:1.5b
ollama pull llama3.2:1b  # Optional alternative
```

### 5Ô∏è‚É£ Index Your Documents

```bash
# Parse metadata
python scripts/parse_excel.py

# Embed and index documents (takes 5-10 minutes)
python scripts/embed.py --mode fresh

# Verify indexing
curl http://localhost:6333/collections/tender_chunks
```

### 6Ô∏è‚É£ Launch Streamlit UI

```bash
streamlit run ui/app_streamlit.py
# Open browser: http://localhost:8501
```

**Ready!** Try queries like:
- `"Was ist DTAD-ID 20046891?"`
- `"Show me tenders from 2024"`
- `"Tenders in Dresden region"`

---

## üñ•Ô∏è UI Preview

* Query tender docs with natural language (DE/EN)
* Filter by metadata (e.g. CPV codes, filenames)
* Adjust `Top-K results` & retrail chunks(optional)
* Answers include **citations + categories + summaries**

---

## üìÇ Project Structure

```
multilingual-ragbot/
‚îú‚îÄ‚îÄ core/                          # Core RAG components
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ qa.py                     # Q&A and retrieval logic
‚îÇ   ‚îú‚îÄ‚îÄ search.py                 # Dense vector search
‚îÇ   ‚îú‚îÄ‚îÄ domain.py                 # Data models
‚îÇ   ‚îú‚îÄ‚îÄ io.py                     # File I/O utilities
‚îÇ   ‚îî‚îÄ‚îÄ logger.py                 # Logging configuration
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îî‚îÄ‚îÄ app_streamlit.py          # üñ•Ô∏è Main Streamlit interface
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ embed.py                  # Document embedding pipeline
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py                 # Document ingestion
‚îÇ   ‚îú‚îÄ‚îÄ parse_excel.py            # Metadata parser
‚îÇ   ‚îî‚îÄ‚îÄ search.py                 # Search utilities
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ metadata/                 # Tender metadata (cleaned_metadata.xlsx)
‚îÇ   ‚îú‚îÄ‚îÄ extract/                  # Extracted document text
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # Original documents
‚îÇ   ‚îî‚îÄ‚îÄ logs/                     # Processing logs
‚îú‚îÄ‚îÄ docs/                          # üìñ Documentation
‚îÇ   ‚îú‚îÄ‚îÄ TESTING_GUIDE.md          # Testing procedures
‚îÇ   ‚îú‚îÄ‚îÄ SYSTEM_REVIEW.md          # System architecture review
‚îÇ   ‚îî‚îÄ‚îÄ TEST_QUERIES.md           # Example test queries
‚îú‚îÄ‚îÄ QUICKSTART.md                  # ‚ö° Quick start guide
‚îú‚îÄ‚îÄ PRODUCTION_GUIDE.md            # üöÄ Production deployment guide
‚îú‚îÄ‚îÄ deploy_production.py           # One-command deployment
‚îú‚îÄ‚îÄ docker-compose.yml             # Qdrant service configuration
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îî‚îÄ‚îÄ README.md                      # This file
```

## üìñ Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 5 minutes
- **[PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md)** - Production deployment
- **[docs/TESTING_GUIDE.md](docs/TESTING_GUIDE.md)** - Testing procedures
- **[docs/TEST_QUERIES.md](docs/TEST_QUERIES.md)** - Example queries

## üéØ Example Queries

The system handles various query types:

**Direct ID Lookups:**
```
"Was ist DTAD-ID 20046891?"
"Show me tender 20047108"
```

**Temporal Queries:**
```
"Show me tenders from 2024"
"What tenders were published in March?"
```

**Geographic Filters:**
```
"Tenders in Dresden"
"Show me projects in Berlin region"
```

**Semantic Questions:**
```
"Welche Unterlagen sind f√ºr VOB-konforme Ausschreibungen erforderlich?"
"What are the technical specifications for IT projects?"
"Mindestlohn requirements in construction tenders"
```

**Metadata Routing:**
- DTAD-ID queries ‚Üí Direct metadata lookup (instant)
- Date/year queries ‚Üí Metadata filtering  
- Semantic queries ‚Üí Vector search with context

---


## üîÆ Roadmap & Future Enhancements

### üéØ Core Improvements (Planned)

**1. Hybrid Search (Dense + Sparse)**
- Add BM25 keyword search alongside current dense vector search
- Weighted fusion for better exact-match queries (CPV codes, DTAD-IDs)
- Expected: +15% recall improvement

**2. Cross-Encoder Reranker**
- Rerank top-K results before LLM generation
- Model: `ms-marco-MiniLM-L-6-v2` or similar
- Expected: +20% precision improvement

**3. Evaluation Framework**
- Test set with 50+ queries covering different scenarios
- Metrics: Hit Rate, MRR, Precision@k, answer faithfulness
- Automated regression testing

**4. Monitoring Dashboard**
- Track query latency, error rates, cache performance
- Log slow queries (>5s) and failures
- Simple Streamlit visualization

### üõ†Ô∏è Future Enhancements

**5. Semantic Chunking**
- Replace fixed 1024-char chunks with sentence-aware splitting
- Better context preservation

**6. Production Alerting**
- Email/Slack notifications for errors
- System health checks

**7. Multimodal Support**
- Extract and parse tables from PDFs
- Handle images and charts in tender documents

**8. Query Enhancement**
- Expand abbreviations and handle umlaut variations
- Better date range handling

---
maybe i find someelsse to improve I will add it later
## The project is still Ongoing ....