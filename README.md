
# ğŸ§  Production-Ready Multilingual RAG System for Tender Documents

**RAGbot** is a production-grade Retrieval-Augmented Generation (RAG) system specifically designed for **German public tender documents** (Vergabeunterlagen) with full multilingual support.

Query unstructured procurement data in **German or English** and receive **accurate, grounded, source-cited answers** through an intuitive chat interface.

This system runs **100% offline** on your local machine using:
- **Qdrant** for vector storage
- **Jina Embeddings v3** (1024-D) for semantic search  
- **Ollama** for local LLM inference (Qwen2.5, Llama, Mistral)
- **Streamlit** for the web interface

âœ… **Production-Ready**: Fixed syntax errors, robust error handling, metadata integration, comprehensive documentation

---

## âœ¨ Key Features

### Core RAG Capabilities
* ğŸ” **Multilingual Semantic Search** - Query in German or English, retrieve from both
* ğŸ“‘ **Rich Document Support** - PDF, Excel, DOCX, scanned files (OCR via Tesseract)
* âš¡ **High-Performance Embeddings** - Jina v3 (1024-D) with GPU acceleration
* ğŸ—„ï¸ **Qdrant Vector DB** - Fast, persistent semantic search with 29,086+ chunks
* ğŸ¤– **Local LLM Generation** - Ollama (Qwen2.5:1.5b default, supports Llama/Mistral)
* ğŸ“Š **Metadata-Aware Routing** - Direct DTAD-ID lookups, date/region filters
* ğŸ¯ **Citation Grounding** - Every answer cites sources with [1], [2] references
* ï¿½ **Privacy-First** - Everything runs locally, zero external API calls

### Production Features
* âœ… **Graceful Error Handling** - Handles missing collections, network issues
* ï¿½ **Metadata Integration** - 112 tenders with normalized DTAD-ID, dates, regions  
* ğŸ§ª **Test Suite** - Comprehensive test queries and validation scripts
* ğŸ“– **Complete Documentation** - Quickstart, production guide, testing guide
* ğŸš€ **One-Command Deployment** - `deploy_production.py` script included

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart LR
    A[ğŸ“„ Tender Docs (PDF, Excel, Word, OCR)] --> B[ğŸ§¹ Parser & Metadata Cleaner]
    B --> C[âœ‚ï¸ Chunking + GPU Embeddings]
    C --> D[(ğŸ—„ï¸ Qdrant Vector DB)]
    D --> E[ğŸ” Retriever (Top-K Search)]
    E --> F[ğŸ¤– Cross-Encoder Reranker]
    F --> G[ğŸ§  LLM via Ollama]
    G --> H[ğŸ“ Answer Generator]
    H --> I[ğŸ’» Streamlit UI]

    subgraph User
        Q[â“ User Query]
        R[ğŸ“‘ Structured Answer + Sources]
    end

    Q --> E
    I --> R
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+ (Conda environment recommended)
- Docker (for Qdrant)
- Ollama (for local LLMs)
- 8GB+ RAM, GPU recommended for embeddings

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/ShalinVachheta017/ragbot-core.git
cd ragbot-core
```

### 2ï¸âƒ£ Set Up Environment

```bash
# Create conda environment
conda create -n mllocalag python=3.10
conda activate mllocalag

# Install dependencies
pip install -r requirements.txt
pip install pytesseract  # For OCR support
```

### 3ï¸âƒ£ Start Qdrant Vector Database

```bash
docker compose up -d
# Verify: http://localhost:6333/dashboard
```

### 4ï¸âƒ£ Install Ollama Models

```bash
# Install Ollama from https://ollama.ai
ollama pull qwen2.5:1.5b
ollama pull llama3.2:1b  # Optional alternative
```

### 5ï¸âƒ£ Index Your Documents

```bash
# Parse metadata
python scripts/parse_excel.py

# Embed and index documents (takes 5-10 minutes)
python scripts/embed.py --mode fresh

# Verify indexing
curl http://localhost:6333/collections/tender_chunks
```

### 6ï¸âƒ£ Launch Streamlit UI

```bash
streamlit run ui/app_streamlit.py
# Open browser: http://localhost:8501
```

**Ready!** Try queries like:
- `"Was ist DTAD-ID 20046891?"`
- `"Show me tenders from 2024"`
- `"Tenders in Dresden region"`

---

## ğŸ–¥ï¸ UI Preview

* Query tender docs with natural language (DE/EN)
* Filter by metadata (e.g. CPV codes, filenames)
* Adjust `Top-K results` & reranker candidates
* Answers include **citations + categories + summaries**

---

## ğŸ“‚ Project Structure

```
multilingual-ragbot/
â”œâ”€â”€ core/                          # Core RAG components
â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”œâ”€â”€ qa.py                     # Q&A and retrieval logic
â”‚   â”œâ”€â”€ search.py                 # Dense vector search
â”‚   â”œâ”€â”€ domain.py                 # Data models
â”‚   â”œâ”€â”€ io.py                     # File I/O utilities
â”‚   â””â”€â”€ logger.py                 # Logging configuration
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app_streamlit.py          # ğŸ–¥ï¸ Main Streamlit interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ embed.py                  # Document embedding pipeline
â”‚   â”œâ”€â”€ ingest.py                 # Document ingestion
â”‚   â”œâ”€â”€ parse_excel.py            # Metadata parser
â”‚   â””â”€â”€ search.py                 # Search utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ metadata/                 # Tender metadata (cleaned_metadata.xlsx)
â”‚   â”œâ”€â”€ extract/                  # Extracted document text
â”‚   â”œâ”€â”€ raw/                      # Original documents
â”‚   â””â”€â”€ logs/                     # Processing logs
â”œâ”€â”€ docs/                          # ğŸ“– Documentation
â”‚   â”œâ”€â”€ TESTING_GUIDE.md          # Testing procedures
â”‚   â”œâ”€â”€ SYSTEM_REVIEW.md          # System architecture review
â”‚   â””â”€â”€ TEST_QUERIES.md           # Example test queries
â”œâ”€â”€ QUICKSTART.md                  # âš¡ Quick start guide
â”œâ”€â”€ PRODUCTION_GUIDE.md            # ğŸš€ Production deployment guide
â”œâ”€â”€ deploy_production.py           # One-command deployment
â”œâ”€â”€ docker-compose.yml             # Qdrant service configuration
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 5 minutes
- **[PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md)** - Production deployment
- **[docs/TESTING_GUIDE.md](docs/TESTING_GUIDE.md)** - Testing procedures
- **[docs/TEST_QUERIES.md](docs/TEST_QUERIES.md)** - Example queries

## ğŸ¯ Example Queries

The system handles various query types:

**Direct ID Lookups:**
```
"Was ist DTAD-ID 20046891?"
"Show me tender 20047108"
```

**Temporal Queries:**
```
"Show me tenders from 2024"
"What tenders were published in March?"
```

**Geographic Filters:**
```
"Tenders in Dresden"
"Show me projects in Berlin region"
```

**Semantic Questions:**
```
"Welche Unterlagen sind fÃ¼r VOB-konforme Ausschreibungen erforderlich?"
"What are the technical specifications for IT projects?"
"Mindestlohn requirements in construction tenders"
```

**Metadata Routing:**
- DTAD-ID queries â†’ Direct metadata lookup (instant)
- Date/year queries â†’ Metadata filtering  
- Semantic queries â†’ Vector search with context

---

## ğŸ”® Roadmap & Future Enhancements

- ğŸ“· **Multimodal RAG** - Support for images (drawings, blueprints, charts)
- ğŸ“ˆ **Analytics Dashboard** - Tender insights, trends, CPV analysis
- ğŸŒ **Web Deployment** - FastAPI backend + production-ready frontend
- ğŸ“Š **Advanced Filters** - CPV hierarchy navigation, multi-region queries
- ğŸ§© **API Connectors** - Integration with tender portals, SharePoint
- ğŸ” **Agentic RAG** - Multi-hop reasoning, complex document comparisons
- ğŸ› ï¸ **Enterprise Features** - RBAC, audit logs, encrypted storage

---

## ğŸ› Troubleshooting

**Qdrant Connection Error:**
```bash
# Check Qdrant is running
curl http://localhost:6333/collections
# Restart if needed
docker compose restart
```

**Empty Search Results:**
```bash
# Verify documents are indexed
curl http://localhost:6333/collections/tender_chunks
# Re-index if point_count is 0
python scripts/embed.py --mode fresh
```

**Ollama Model Not Found:**
```bash
ollama list  # Check installed models
ollama pull qwen2.5:1.5b  # Install if missing
```

**Import Errors:**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“œ License

MIT License - free to use and adapt with attribution.

---

## ğŸ‘¤ Author

**Shalin Vachheta**  
GitHub: [@ShalinVachheta017](https://github.com/ShalinVachheta017)

---

## ğŸ™ Acknowledgments

- **Jina AI** - Embeddings model
- **Qdrant** - Vector database
- **Ollama** - Local LLM inference
- **Streamlit** - UI framework
- German procurement community for test data

---

**â­ Star this repo if you find it useful!**

